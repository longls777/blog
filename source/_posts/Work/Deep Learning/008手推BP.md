---
title: 手推BP(Backpropagation)
tags: 
categories: Deep Learning
date: 2023-7-22 11:23:00
index_img: http://longls777.oss-cn-beijing.aliyuncs.com/img/v2-2d355d35fddfe8bc5fa93a3670cbb5c2_720w.webp
banner_img: http://longls777.oss-cn-beijing.aliyuncs.com/img/v2-2d355d35fddfe8bc5fa93a3670cbb5c2_720w.webp
math: true
---

> https://towardsdatascience.com/deriving-the-backpropagation-equations-from-scratch-part-1-343b300c585a
>
> https://towardsdatascience.com/backpropagation-step-by-step-derivation-99ac8fbdcc28
>
> https://juejin.cn/post/6844903780157227022

![3 layers MLP](http://longls777.oss-cn-beijing.aliyuncs.com/img/v2-2d355d35fddfe8bc5fa93a3670cbb5c2_720w.webp)

![](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230722113744785.png)

$w^l_{jk}$ 表示第$l$层的第$j$个神经元连接到第$(l-1)$层的第$k$个神经元的权重，如上图$w^3_{24}$

$b^l_j$表示第$l$层的第$j$个神经元的偏置（bias）

$z^l_j$表示第$l$层的第$j$个神经元的输入，即：$z^l_j=\sum_{k} w^l_{jk}a^{l-1}_k + b^l_j$

$a^l_j$表示第$l$层的第$j$个神经元的输出，即：$a^l_j = \sigma(z^l_j) =\sigma(\sum_{k} w^l_{jk}a^{l-1}_k + b^l_j)$

$\sigma$表示激活函数

$C$表示损失函数，用来计算最终输出与实际值的误差

$L$表示神经网络的最大层数

第$l$层的第$j$个神经元产生的误差定义为$\delta^l_j = \frac{\partial C}{\partial z^l_j}$

## 最后一层神经网络产生的误差


$$
\begin{aligned}
& \delta_j^L=\frac{\partial C}{\partial z_j^L}=\frac{\partial C}{\partial a_j^L} \cdot \frac{\partial a_j^L}{\partial z_j^L}=\frac{\partial C}{\partial a_j^L} \cdot \sigma^{\prime}\left(z_j^L\right) \\
& \delta^L=\frac{\partial C}{\partial a^L} \odot \frac{\partial a^L}{\partial z^L}=\nabla_a C \odot \sigma^{\prime}\left(z^L\right)
\end{aligned}
$$
因此
$$
\delta^L=\nabla_a C \odot \sigma^{\prime}\left(z^L\right)
$$
其中$ \odot $表示Hadamard乘积，用于矩阵或向量之间点对点的乘法运算



## 由后往前，计算前后两层神经网络直接的误差关系


$$
\begin{aligned}
\delta_j^l=\frac{\partial C}{\partial z_j^l} & =\sum_k \frac{\partial C}{\partial z_k^{l+1}} \cdot \frac{\partial z_k^{l+1}}{\partial a_j^l} \cdot \frac{\partial a_j^l}{\partial z_j^l} \\
& =\sum_k \delta_k^{l+1} \cdot \frac{\partial\left(w_{k j}^{l+1} a_j^l+b_k^{l+1}\right)}{\partial a_j^l} \cdot \sigma^{\prime}\left(z_j^l\right) \\
& =\sum_k \delta_k^{l+1} \cdot w_{k j}^{l+1} \cdot \sigma^{\prime}\left(z_j^l\right)
\end{aligned}
$$
因此：
$$
\delta^l=\left(\left(w^{l+1}\right)^T \delta^{l+1}\right) \odot \sigma^{\prime}\left(z^l\right)
$$


## 计算权重的梯度

$$
\frac{\partial C}{\partial w_{j k}^l}=\frac{\partial C}{\partial z_j^l} \cdot \frac{\partial z_j^l}{\partial w_{j k}^l}=\delta_j^l \cdot \frac{\partial\left(w_{j k}^l a_k^{l-1}+b_j^l\right)}{\partial w_{j k}^l}=a_k^{l-1} \delta_j^l
$$

因此：
$$
\frac{\partial C}{\partial w_{j k}^l}=a_k^{l-1} \delta_j^l
$$


## 计算偏置的梯度

$$
\frac{\partial C}{\partial b_j^l}=\frac{\partial C}{\partial z_j^l} \cdot \frac{\partial z_j^l}{\partial b_j^l}=\delta_j^l \cdot \frac{\partial\left(w_{j k}^l a_k^{l-1}+b_j^l\right)}{\partial b_j^l}=\delta_j^l
$$

因此：
$$
\frac{\partial C}{\partial b_j^l}=\delta_j^l
$$
