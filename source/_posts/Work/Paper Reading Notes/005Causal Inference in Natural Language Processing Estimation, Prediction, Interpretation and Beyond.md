---
title: Causal Inference in Natural Language Processing - Estimation, Prediction, Interpretation and Beyond
tags: Causal Inference
categories: Paper Reading Notes
date: 2023-04-13 14:36:00
index_img: 
banner_img: 
math: true
---

**标题：**《Causal Inference in Natural Language Processing: Estimation, Prediction, Interpretation and Beyond》

**论文来源：** TACL 2022

**原文链接：** https://aclanthology.org/2022.tacl-1.66.pdf



## 背景

科学研究的一个基本目标是了解因果关系。然而，尽管因果关系在生命和社会科学中发挥着关键作用，但在自然语言处理(NLP)中**并没有同样的重要性**，传统上更强调**预测任务**

**在许多经典的NLP应用程序中，主要目标是做出准确的预测：任何统计相关性都是可接受的，不管潜在的因果关系**

然而，随着NLP系统越来越多地部署在具有挑战性和高风险的场景中，我们**不能依赖于通常的假设，即训练和测试数据是相同分布的**，我们可能不会满足于不可解释的黑盒预测器。对于这两个问题，因果关系提供了一条有希望的前进道路：**数据生成过程的因果结构领域知识可以提出归纳偏置，从而导致更强健的预测器；而对预测器本身的因果视角可以提供有关其内部运作的新见解。**

将因果关系和NLP的交集分为两个领域: **从文本中估计因果影响，以及使用因果形式主义使NLP方法更加可靠**



## 估计文本中存在的因果效应

**因果效应与文本混淆词**

主要思想是使用NLP方法从文本中提取混淆的方面，然后在倾向分数匹配等估计方法中对这些方面进行调整。然而，这些方法如何以及何时违反因果假设仍然是悬而未决的问题

### 使用因果推理帮助解决传统的NLP任务

##### **数据增强**

1. 构造反事实数据

反事实数据是一种强大的资源，因为它们直接解决了因果推理中固有的缺失数据问题，

**存在的问题**

- 在许多情况下，即使是一个流利的人也很难产生有意义的反事实
- 无法精确地说明反事实的预期影响
- 反事实有可能会引入新的虚假相关性

2. 设计新的学习算法，直接对观察到的数据进行操作（推导不变性预测器的分布特性，然后确保训练的模型满足这些特性）