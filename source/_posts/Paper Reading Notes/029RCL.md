---
title: RCL - Relation Contrastive Learning for Zero-Shot Relation Extraction
tags: RE
categories: Paper Reading Notes
date: 2023-09-1 23:09:00
index_img: https://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230831114455586.png
banner_img: 
math: true
---

**标题：**《RCL: Relation Contrastive Learning for Zero-Shot Relation Extraction》

**论文来源：** NAACL Findings 2022

**原文链接： **  https://aclanthology.org/2022.findings-naacl.188/

**源码：** https://github.com/ShusenWang/NAACL2022-RCL



## 概述

Zero-shot任务存在两种相似性错误：

- 关系相似
- 实体相似

通过对比学习，增强模型对相似关系的区分能力

![](https://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230831114340962.png)

## Method

![](https://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230831114455586.png)

- 训练时，分类和对比学习 多任务训练
- 推理时，通过Encoder和Concat Layer得到的representation进行k-means聚类，来预测unseen relation



### Input Sentence Encoder

![](https://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230901163622289.png)

- 使用四个special token标记entity的位置
- 使用BERT编码

![](https://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230901164324166.png)

### Contrastive Learning Module

- 两层：data augmentation layer 和 concat layer
- data augmentation layer ： 相当于一个变换$\hat{h_i}=T(h_i)$，得到augmented view $\hat{h_i}$
- 然后取$<e_1>$和 $<e_2>$对应的embedding拼起来得到relation表征（这里的concat layer就是一个concat操作）

![](https://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230901165042187.png)

- 然后拉近相同relation的距离，拉远不同relation的距离
- $r_i$和对应的$\hat{r_i}$是一对正例，同一个batch里其他的是反例

![](https://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230901165634873.png)

- 用交叉熵做损失函数，从而达到$r_i$更接近$\hat{r_i}$，更远离$\hat{r_j}$

#### Data Augmentation Strategies

- 为了放大相似relation之间的语义差距，但是不破坏relation表征，采用了5种数据增强方法：
  - feature cutoff ： 随机删除一些特征维度
  - random mask ：随机把一些token embedding设为0
  - dropout ： 再次将相同的句子输入BERT（出来的结果不一样吗？？因为BERT里有dropout所以不一样？还能这样）
  - dropout + feature cutoff ： 这就比较好理解了，先输入BERT得到新的embedding然后再cutoff
  - dropout + random mask ： 和上面类似



###  Relation Classification Module

- 把encoder编码后得到的表征提取$<e_1>$和 $<e_2>$的token embedding 拼起来
- 然后通过一个FC和softmax

![](https://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230901172754654.png)



![](https://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230901172803536.png)

- 总的Loss

![](https://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230901174544660.png)



## Experiments

![](https://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230831114657707.png)

这个$B^3$准确率？？？

> $B^3$ precision and recall correspondingly measure the correct rate of putting each sentence in its cluster or clustering all samples into a single class. 

![](https://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230901212829550.png)





![](https://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230831114734536.png)

RCL随着m越大，提升越大



![](https://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230901220942096.png)

Dropout效果最好



![](https://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230901221030206.png)

#### 补充实验

应该不是Zero-Shot

![](https://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230901225850897.png)

![](https://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230901225902560.png)