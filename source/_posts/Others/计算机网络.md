---
title: 计算机网络
tags: 八股
categories: Others
date: 2023-4-30 14:02:00
index_img: 
banner_img: 
math: true
---

# 一、计算机网络分层

**1. 说说计算机网络的分层模型？**

OSI模型有七层，TCP/IP协议簇有四层，综合起来是一个五层的网络模型

![计算机网络协议分层](http://longls777.oss-cn-beijing.aliyuncs.com/img/计算机网络协议分层.png)

**应用层**

为特定应用程序提供数据传输服务，有一些应用层协议定义应用程序间的通信和交互的规则，比如HTTP、DNS、SMTP等，数据单位是报文

**运输层**

为两台主机的**进程**之间的通信提供**通用**的数据传输服务，向高层用户屏蔽了下面网络层的核心细节，运输层包括两种协议：

- 传输控制协议TCP：提供面向连接的，可靠的数据传输服务
- 用户数据报协议UDP：提供无连接的，尽最大努力的数据传输服务

数据单位是报文段

**网络层**

在计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是选择合适的网间路由和交换结点， 确保数据及时传送。 在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP/IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫 IP 数据报 ，简称数据报

**链路层**

数据链路层（data link layer）通常简称为链路层。两台主机之间的数据传输，总是在一段一段的链路上传送的，这就需要使用专门的链路层的协议。 在两个相邻节点（主机或路由器）之间传送数据时，数据链路层将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧。每一帧包括数据和必要的控制信息（如同步信息，地址信息，差错控制等），提供物理地址寻址功能（ARP）

**物理层**

在物理层上所传送的数据单位是比特。物理层就是数据实际传输的通道。

物理层（physical layer）的作用是实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异， 使其上面的数据链路层不必考虑网络的具体传输介质是什么。

![OSI七层协议](http://longls777.oss-cn-beijing.aliyuncs.com/img/OSI七层协议.png)

**2. 会话层的作用？**

- 建立会话：**身份验证**，**权限鉴定**等；
- 保持会话：对该会话进行维护，在会话维持期间两者可以随时使用这条会话传输；
- 断开会话：当应用程序或应用层规定的超时时间到期后，OSI会话层才会释放这条会话。

# 二、TCP和UDP

**1. 说说TCP和UDP的区别？**

![TCP和UDP的对比](http://longls777.oss-cn-beijing.aliyuncs.com/img/TCP和UDP的对比.jpeg)

**UDP**

是无连接的，尽最大努力交付，没有拥塞控制，是面向报文的，对于应用层传输下来的报文只添加UDP首部，支持广播和多播，UDP包的最大传输数据量：1500 - IP头(20) - UDP头(8) = 1472(Bytes)

**TCP**

是面向连接的，在传送数据之前必须先建立连接，数据传送结束后要释放连接。 提供可靠数据交付服务，有流量控制，拥塞控制，提供全双工通信，是面向字节流的，把应用层传输下来的报文看成字节流，把这些字节流组织成大小不等的数据块，只支持点对点通信（单播），TCP包的最大传输数据量1500 - IP头(20) - TCP头(20) = 1460 (Bytes)

**2. UDP的使用场景？**

- 某些实时应用要求最小的发送速率，**不希望延迟**报文段的传送，且**能容忍一些报文段的丢失**，UDP会立即将数据传递给网络层，而TCP有拥塞控制，可能会遏制数据报的发送
- **UDP无连接**，相比需要三次握手的TCP，UDP不会引入连接的时延，这是DNS使用UDP的主要原因，而HTTP要求传输数据的可靠性，所以使用TCP
- UDP无需维持连接状态，因此省去了一些资源，所以有些特定服务器使用UDP以服务更多用户
- UDP分组首部开销只有8字节，而TCP有20字节

**3. TCP粘包？**

**什么是TCP粘包？**

TCP粘包就是指发送方发送的若干包数据到达接收方时粘成了一包，从接收缓冲区来看，后一包数据的头紧接着前一包数据的尾，出现粘包的原因是多方面的，可能是来自发送方，也可能是来自接收方。

**为什么会发生TCP粘包？**

- 发送方：TCP默认使用Nagle算法来减少网络中报文段的数量，将多次间隔较小且数据量小的数据，合并成一个大的数据块，然后进行封包
- 接收方：TCP将接收到的数据包保存在接收缓存里，然后应用程序主动从缓存读取收到的分组。这样一来，如果TCP接收数据包到缓存的速度大于应用程序从缓存中读取数据包的速度，多个包就会被缓存，应用程序就有可能读取到多个首尾相接粘到一起的包。

**什么时候要处理粘包？**

- 如果发送方发送的多组数据本来就是同一块数据的不同部分，比如说一个文件被分成多个部分发送，这时当然不需要处理粘包现象
- 如果多个分组毫不相干，甚至是并列关系，那么这个时候就一定要处理粘包现象

**如何处理粘包？**

- 发送方：关闭Nagle算法

- 应用层：

- - 每条数据有固定的格式（开始符，结束符），这种方法简单易行，但是选择开始符和结束符时一定要确保每条数据的内部不包含开始符和结束符
  - 发送每条数据时，将数据的长度一并发送，例如规定数据的前4位是数据的长度，应用层在处理时可以根据长度来判断每个分组的开始和结束位置

**为什么UDP没有粘包现象？**

- TCP为了保证可靠传输并减少额外的开销，采用了基于流的传输，基于流的传输不认为消息是一条一条的，是无保护消息边界的
- UDP则是面向消息传输的，是有保护消息边界的，接收方一次只接受一条独立的信息，所以不存在粘包问题

> 保护消息边界：指传输协议把数据当做一条独立的消息在网上传输，接收端一次只能接受一条独立的消息

# 三、TCP报文头

**TCP报文头格式**

![TCP报文头格式](http://longls777.oss-cn-beijing.aliyuncs.com/img/TCP报文头格式.png)

**相关字段的作用**

**序号**

一个报文段的序号（sequence number）是该报文段首字节的字节流编号

**确认号**

主机A填充进报文段的确认号（ack number）是主机A期望从主机B收到的下一报文段的序号

**ACK**

确认标志，用于指示确认字段中的值是有效的，即该报文段包括一个对已被成功接收报文段的确认

**SYN**

同步标志，该标志仅在三次握手建立TCP连接时有效。它提示TCP连接的服务端检查序列编号，该序列编号为TCP连接初始端（一般是客户端）的初始序列编号

**FIN**

结束标志，带有该标志置位的数据包用来结束一个TCP回话，但对应端口仍处于开放状态，准备接收后续数据

# 四、TCP三次握手四次挥手

**1.说说TCP的三次握手和四次挥手？**

**三次握手**

![](http://longls777.oss-cn-beijing.aliyuncs.com/img/TCP三次握手.png)

1. 第一次握手：客户端将标志位SYN置为1，随机产生一个值序列号seq=x，并将该数据包发送给服务端，客户端进入syn_sent状态，等待服务端确认。
2. 第二次握手：服务端收到数据包后由标志位SYN=1知道客户端请求建立连接，服务端将标志位SYN和ACK都置为1，ack=x+1，随机产生一个值seq=y，并将该数据包发送给客户端以确认连接请求，服务端进入syn_rcvd状态。
3. 第三次握手：客户端收到确认后检查，如果正确则将标志位ACK为1，ack=y+1，并将该数据包发送给服务端，服务端进行检查如果正确则连接建立成功，客户端和服务端进入established状态，完成三次握手，随后客户端和服务端之间可以开始传输数据了

**为什么要三次握手？**

1.在谢希仁著《计算机网络》第四版中讲**“三次握手”的目的是“为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误”**。在另一部经典的《计算机网络》一书中讲“三次握手”的目的是为**了解决“网络中存在延迟的重复分组”的问题**。这两种不用的表述其实阐明的是同一个问题。

谢希仁版《计算机网络》中的例子是这样的，“已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。”这个例子很清晰的阐释了“三次握手”对于建立可靠连接的意义。

2.这个问题的本质是，信道不可靠，但是通信双方需要就某个问题达成一致，而要解决这个问题，无论你在消息中包含什么信息，三次通信是理论上的最小值。所以三次握手不是TCP本身的要求，而是**为了满足"在不可靠信道上可靠地传输信息"这一需求**所导致的。请注意这里的本质需求，信道不可靠，数据传输要可靠。三次达到了，那后面你想接着握手也好，发数据也好，跟进行可靠信息传输的需求就没关系了。因此，如果信道是可靠的，即无论什么时候发出消息，对方一定能收到，或者你不关心是否要保证对方收到你的消息，那就能像UDP那样直接发送消息就可以了”。这可视为对“三次握手”目的的另一种解答思路。（三次以上握手造成资源浪费）

**四次挥手**

![](http://longls777.oss-cn-beijing.aliyuncs.com/img/TCP四次挥手.png)

以下描述不讨论序号和确认号，因为序号和确认号的规则比较简单。并且不讨论 ACK，因为 ACK 在连接建立之后都为 1

- A 发送连接释放报文，FIN=1
- B 收到之后发出确认，此时 TCP 属于半关闭状态，B 能向 A 发送数据但是 A 不能向 B 发送数据
- 当 B 不再需要连接时，发送连接释放报文，FIN=1
- A 收到后发出确认，进入 TIME-WAIT 状态，等待 2 MSL（最大报文存活时间）后释放连接
- B 收到 A 的确认后释放连接

**为什么要四次挥手？**

因为TCP是全双工模式，接收到FIN时意味将没有数据再发来，但是还是可以继续发送数据。TCP在断开连接时，需要客户端和服务器都确定对方将不再发送数据。

当服务器收到FIN报文时，它可能还有数据没发送完，可能并不会立即关闭socket，所以先回复一个ACK报文，告诉客户端，“你发的FIN报文我收到了”，然后等数据都发送完了，服务器再发送FIN报文，告诉客户端，“我的数据发送完了”。

当服务器收到FIN报文之后，它就进入了CLOSE_WAIT状态，这个状态就是为了让服务器发送还未传输完毕的数据，发送完毕之后，服务器就会发送FIN报文

![](http://longls777.oss-cn-beijing.aliyuncs.com/img/kehuduantcp.png)

![](http://longls777.oss-cn-beijing.aliyuncs.com/img/fuwuduantcp.png)

**2.说说TIME_WAIT和CLOSE_WAIT?**

**TIME_WAIT**

客户端收到服务器端的FIN报文后进入此状态，之后等待2MSL的时间，这样做的原因是：

- 为使旧的数据包在网络因过期而消失：如果客户端不存在TIME_WAIT，假设关闭一条TCP连接之后立即以相同的四元组(local_ip, local_port, remote_ip,remote_port)建立一条新的连接，在这种情况下，可能有延迟的旧TCP连接的包在新TCP连接建立之后到达，服务器端不能分辨来自前后两条TCP连接的包，可能会将之前TCP连接中发来的包上传到应用层，这样就可能引起数据错乱，TIME_WAIT正是为了避免这种情况的发生
- 为实现TCP全双工连接的可靠释放：确保最后一个确认报文能够到达，如果服务器端没收到客户端发送来的ACK报文，那么就会重发FIN报文，客户端等待一段时间就是为了处理这种情况，收到重发的FIN报文后，客户端可以再发一个ACK报文

**出现大量TIME_WAIT有什么危害？如何解决？**

危害：

- 在socket的TIME_WAIT状态结束之前，该socket所占用的本地端口号将一直无法释放。
- 在高并发（每秒几万qps）并且采用短连接方式进行交互的系统中运行一段时间后，系统中就会存在大量的time_wait状态，如果time_wait状态把系统所有可用端口都占完了且尚未被系统回收时，就会出现无法向服务端创建新的socket连接的情况。此时系统几乎停转，任何链接都不能建立。
- 大量的time_wait状态也会占有系统一定的fd，内存和cpu资源

解决方法：

- 调整系统内核参数，比如：开启重用，允许将TIME-WAIT sockets重新用于新的TCP连接
- 开启TCP连接中TIME-WAIT sockets的快速回收
- 调整短连接为长连接

**CLOSE_WAIT**

close_wait是被动关闭连接形成的，服务器端收到客户端发送的FIN，TCP协议栈会自动发送ACK，连接进入close_wait状态。但如果服务器端不执行socket的close()操作，状态就不能由close_wait迁移到last_ack，则系统中会存在很多close_wait状态的连接

出现大量close_wait可能的原因：

- 代码层面忘记了 close 相应的 socket 连接
- 如果Server端一直没有向client端发送FIN消息(调用close() API)，那么这个CLOSE_WAIT会一直存在下去

**3. 什么是SYN泛洪攻击？如何防御？**

SYN泛洪攻击是当前网络上最为常见的DDoS（分布式拒绝服务）攻击，SYN攻击利用TCP协议缺陷，通过发送大量的半连接请求，占用半连接队列（SYN-RECIEVED队列），耗费CPU和内存资源。

应对方法：

- 缩短SYN Timeout时间，使得主机尽快释放半连接的占用
- IP黑名单，若连续受到某个IP的重复SYN报文，从这个IP地址来的包会被一概丢弃
- CDN 将网站访问流量分配到了各个节点中，这样一方面隐藏网站的真实 IP，另一方面即使遭遇 DDoS 攻击，也可以将流量分散到各个节点中，防止源站崩溃

# 五、TCP协议的传输可靠性

**1.说说TCP协议如何保证传输的可靠性？**

- **校验和**：TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段
- **序列号**：TCP 给发送的每一个包进行编号，接收端会根据序列号排序，并丢弃重复的数据
- **确认应答**：收到一条报文后，向发送端发送一条确认ACK，此ACK的作用就是告诉发送端：接收端已经成功的收到了消息，并且希望收到下一条报文的序列号是什么
- **超时重传**：当 TCP 发出一个报文段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个ACK，将重发这个报文段
- **流量控制：**TCP 连接的每一方都有固定大小的缓冲空间，TCP根据接收端对数据的处理能力，也就是接收端剩余缓存空间的大小来控制发送端的发送速度，TCP报文头有一个16位的窗口字段，接收端用它来告诉发送端自己剩余的缓存空间大小，这个流量控制协议就是滑动窗口协议
- **拥塞控制：**
  - **慢启动：** 刚开始时，发送端的拥塞窗口（cwnd）设置为一个MSS（最大报文长度），随后收到一个ACK就增加一个MSS，即成指数增长。当出现一个超时丢包时，将此时cwnd的一半设置为慢启动阈值，然后将cwnd设置为1，重新开启慢启动过程：当cwnd到达慢启动阈值时，就进入拥塞避免模式，或者检测到三个冗余ACK，此时执行快速重传并进入快速恢复状态
  - **拥塞避免：**这时cwnd大概是上次遇到拥塞时的一半，所以要稳妥的增加cwnd，经过每个RTT，将cwnd增加一个MSS，当出现超时丢包时，与慢启动的策略一样；当检测到三个冗余ACK时，将慢启动阈值设置为cwnd的一半，并将cwnd的值减少一半，进入快速恢复状态
  - **快速重传和快速恢复：**发送方只要收到一连三个重复的ACK，就立即重传丢失的报文段，而不必继续等待重传计时器时间到期；当在拥塞避免状态下，收到三个冗余ACK后，执行快速重传和快速恢复，具体操作是：将慢启动阈值设置为cwnd的一半，但并不使用慢启动算法，而是将cwnd减半，重新进入拥塞避免状态，线性增大cwnd

> RTT：往返时间
>
> MSS：最大报文长度，一般为1460字节
>
> MTU：链路层帧最大长度，一般为1500字节 
>

![](http://longls777.oss-cn-beijing.aliyuncs.com/img/yongsekongzhi.png)

**2. TCP检验和的计算？**

TCP在计算检验和时，要加上一个12字节的伪首部

![TCP检验和](http://longls777.oss-cn-beijing.aliyuncs.com/img/TCP检验和.png)

伪首部共有12字节，包含IP首部的一些字段，有如下信息：32位源IP地址、32位目的IP地址、8位保留字节(置0)、8位传输层协议号（TCP是6，UDP是17）、16位TCP报文长度(TCP首部+数据)。伪首部是为了增加TCP校验和的检错能力：通过伪首部的目的IP地址来检查TCP报文是否收错了、通过伪首部的传输层协议号来检查传输层协议是否选对了。

TCP首部校验和计算三部分：TCP首部+TCP数据+TCP伪首部。

- 发送端：

- - 首先，把伪首部、TCP报头、TCP数据分为16位的字，如果总长度为奇数个字节，则在最后增添一个位都为0的字节
  - 把TCP报头中的校验和字段置为0
  - 其次，用反码相加法（对每16bit进行二进制反码求和）累加所有的16位字（进位也要累加，进位则将高位叠加到低位）
  - 最后，将上述结果作为TCP的校验和，存在检验和字段中

- 接收端： 

- - 将所有原码相加，高位叠加到低位， 如计算结果的16位中每一位都为1，则正确，否则说明发生错误

UDP校验和运算的基本过程和TCP检验和相同，不同的是UDP的伪首部中8位传输层协议号是17而TCP是6

IP首部中的检验和只覆盖IP的首部，不覆盖IP数据报中的任何数据

TCP的检验和是必需的，而UDP的检验和是可选的

**3. GBN、SR和TCP的区别？**

- GBN：回退N步

- - 最多允许N个分组未确认
  - 采用累计应答的方式，ACK(n)则表示从开始到n（包含n）的序列号全部正确接收

> 这里顺便解释一下为什么GBN可以采用累计应答的方式？怎么就能保证之前的被正确接收了呢？这还要由GBN的工作机制来决定：在GBN机制下，在接收端的运输层一次只交付给上层一个分组，并且保证是按序交付的，因此如果分组k已接收，则所有序号小于k的分组也已经交付了

- - 在传分组有一个计时器，如果收到了timeout(n)事件，那么会重传的是n以及n以后的所有分组（尽管后面的可能已经收到了，这就是GBN，回退到n开始传）
  - 接收方会有一个期望序列号，如果收到的不是期望的分组，直接丢弃，也就是说接收端不对失序到达的分组进行缓存

- SR：选择重传

- - 接收方设置缓存区，用于接收失序到达的分组。（从这里可以感受到，所谓的GBN中的发送端窗口和SR中的发送端与接收端的窗口其实就是缓存区，用于缓存分组。注意，由于GBN是单个分组交付，不设置缓存区，所以GBN的接收端是没有窗口的）
  - 为每个报文段设置单独的计时器，单个分组计时器超时只重发这一个报文段。
  - 接收端返回ACK是当前接收成功报文段的序号，SR不采用累计应答的方式。	

> 理论上SR协议要为每个分组使用一个计时器。当某个计时器超时后，只有相应的分组被重传。换而言之，GBN协议将所有的分组当做一个整体对待，而选择重传协议则分别对待每一个分组，但是大多数SR的运输层仅使用了一个计时器。注意只使用一个计时器而做到跟踪所有发出去的分组的情况的做法是：标记发出分组，当ACK=Sf 时，将窗口滑过所有连续的已确认的分组，如果还有未确认的分组，则重发所有检测到的未被确认的分组并重启计时器，如果所有分组都被确认了则停止计时器。

- TCP：

- - TCP使用累计应答的方式。这一点与GBN类似
  - TCP在接收端会设置缓存，来缓存正确接收但是失序的分组，这点与SR类似。（实际上TCP RFC并没有对接收端要怎样处理失序到达的分组提出要求，但是在接收端设置缓存是实践中大家都采用的方法）
  - TCP使用快速重传机制：如果收到对于一个特定报文段的3个冗余ACK，则在超时事件发生前就会对该报文段进行重传，这大大节约了时间
  - TCP中的ACK是指接收端希望从发送端收到的下一字节的序号。例如发送端发送了编号为0-5的字节，这时接收端成功接收后就会发送ACK为6

- # 六、DNS域名解析

- ​	**1. 说说DNS域名解析？**

- DNS占用53号端口，使用TCP和UDP协议

- **DNS区域传输时使用TCP协议**

- - 辅域名服务器会定时向主域名服务器进行查询以便了解数据是否有变动，如果有变动，会执行一次区域传输，进行数据同步。区域传输使用TCP而不是UDP，是因为数据同步传送的数据量很大，比一个请求应答的数据量要多得多

- - TCP是可靠连接，保证了数据的准确性

- **域名解析时使用UDP协议**

- 客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。不经过三次握手，这样DNS服务器负载更低，响应更快

- **2.DNS域名解析过程？**

- 1、客户机发出查询请求，在本地计算机缓存查找，若没有找到，就会将请求发送给本地dns服务器

- 2、本地dns服务器会在自己的区域里面查找，找到即根据此记录进行解析，若没有找到，就会在本地的缓存里面查找

- 3、本地dns服务器没有找到客户机查询的信息，就会将此请求发送到根域名dns服务器

- 4、根dns服务器解析客户机请求的根域部分，它把包含的下一级的dns服务器的地址返回到本地dns服务器地址

- 5、本地dns服务器根据返回的信息接着访问下一级的dns服务器

- 6、这样递归的方法一级一级接近查询的目标，最后在有目标域名的服务器上面得到相应的IP信息

- 7、客户机的本地的dns服务器会将查询结果返回给我们的客户机

- 8、客户机根据得到的ip信息访问目标主机，完成解析过程

- **3. DNS的两种查询方式?**

- - **递归查询**：客户机向DNS服务器发送请求，DNS服务器会使用一个**准确的查询结果**回复给客户机，如果DNS服务器本地没有储存查询的DNS信息，那么它会查询其他的DNS服务器，并将查询结果提交给客户机

- - **迭代查询**：客户机向DNS服务器发送请求，如果该服务器本地没有储存查询的DNS信息，那么它会告诉客户机**另一台DNS服务器**的地址，客户机在向这台DNS服务器查询DNS信息，依次循环直到返回结果

- ![DNS递归查询](http://longls777.oss-cn-beijing.aliyuncs.com/img/DNS递归查询.png)

![DNS迭代查询](http://longls777.oss-cn-beijing.aliyuncs.com/img/DNS迭代查询.png)

# 七、Cookie和Session

**说说Cookie和Session的区别？**

Cookie 和 Session都是用来跟踪浏览器用户身份的会话方式，但是两者的应用场景不太一样。

Cookie 一般用来保存用户信息，它是服务器发送到客户端浏览器并保存在用户本地的一块数据，客户端请求服务器，如果服务器需要记录该用户状态，就在返回的响应报文的Set-Cookie首部行为该用户设置Cookie。客户端浏览器会把Cookie保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器。服务器检查该Cookie，以此来辨认用户状态。Cookie可以用作会话状态管理、用户个性化设置等。

Session 的主要作用就是在服务器端记录用户的状态，在用户第一次访问服务器的时候自动创建对应的Session。 典型的场景是购物车，当你要添加商品到购物车的时候，系统不知道是哪个用户操作的，因为 HTTP 协议是无状态的。服务端给特定的用户创建特定的 Session 之后就可以标识这个用户并且跟踪这个用户了。

**区别：**

- Cookie 存储在客户端中，而Session存储在服务器上，相对来说 Session 安全性更高
- Cookie有大小限制，单个不超过4K，浏览器中对单个站点Cookie个数也有限制；Session没有大小限制，跟服务器内存有关，会占用服务器性能
- Cookie生命周期可以设置，默认是一次会话的时间，在浏览器关闭的时候清除；Session的生命周期是间隔性的，在用户第一次访问服务器的时候创建，一段时间后没有再次访问，Session就会被清除

# 八、浏览器输入URL到显示页面的过程

总体来说分为以下几个过程:

1. DNS解析
2. TCP连接
3. 发送HTTP请求
4. 服务器处理请求并返回HTTP报文
5. 浏览器解析渲染页面
6. 浏览器发送异步请求

**DNS解析**

首先是DNS解析，当在浏览器第一次输入一个URL后，客户端向本地DNS服务器递归查询主机名对应的IP地址，本地DNS服务器再向根DNS服务器、顶级域服务器、权威DNS服务器迭代查询。查询过一次之后，在DNS查询过程中经过的节点就会留下缓存，如：浏览器缓存，系统缓存，路由器缓存，ISP DNS服务器缓存，根DNS服务器缓存，顶级域服务器缓存，权威DNS服务器缓存，再次查询时，如果经过的查询节点存在对应的DNS缓存，就可以直接返回解析的IP地址。

**DNS负载均衡**

服务器分布在各个地方，不可能每次访问都指向同一台服务器，实际上DNS可以根据地理距离、服务器负载等，动态地将用户定向到某个服务器集群，这就是DNS的负载均衡，也叫DNS重定向，典型的就是CDN内容分发网

**TCP连接和HTTP请求**

浏览器根据解析到的IP地址向web服务器发送一个HTTP请求

（HTTP请求报文，TCP三次握手等）

**服务器处理请求并返回HTTP报文**

HTTP响应报文，状态码等

**浏览器解析渲染页面**

​          

**浏览器发送异步请求**

持续更新一些页面信息（例如AJAX）

# 九、转发与重定向

**说说转发与重定向的区别？**

**一、重定向与转发的区别**

**转发过程：** 客户端浏览器发送http请求 → web服务器接受此请求 → 调用内部的一个方法在容器内部完成请求处理和转发动作 → 将目标资源发送给客户

转发页面和转发到的页面可以共享request里面的数据

```java
//java代码示例
request.getRequestDispatcher("xxx.jsp或者servlet").forward(request,response);
```

**重定向过程**： 客户端浏览器发送http请求 → web服务器接收后发送30X状态码响应及对应新的location给客户浏览器 → 客户浏览器发现是30X响应，则自动再发送一个新的http请求，请求url是新的location地址→ 服务器根据此请求寻找资源并发送给客户

重定向不能共享request里面的数据

```java
//java代码示例
response.sendRedirect("xxx.jsp或者servlet");
```

**转发和重定向对比：**

![转发和重定向对比](http://longls777.oss-cn-beijing.aliyuncs.com/img/转发和重定向对比.png)

**二、什么时候使用重定向，什么时候使用转发？**

原则上： 要保持request域的数据时使用转发，要访问外站资源的时候用重定向，其余随便；

特殊的应用： 对数据进行修改、删除、添加操作的时候，应该用response.sendRedirect()。如果是采用了request.getRequestDispatcher().forward(request,response)，那么操作前后的地址栏都不会发生改变，仍然是修改的控制器，如果此时再对当前页面刷新的话，就会重新发送一次请求对数据进行修改，这也就是有的人在刷新一次页面就增加一条数据的原因。

**三、转发与重定向的安全性**

**转发安全性**： 在服务器内部实现跳转，客户端不知道跳转路径，相对来说比较安全。

**重定向安全性**： 客户端参与到跳转流程，给攻击者带来了攻击入口，受威胁的可能性较大。

比如一个HTTP参数包含URL，Web应用程序将请求重定向到这个URL，攻击者可以通过修改这个参数，引导用户到恶意站点，并且通过将恶意域名进行十六进制编码，一般用户很难识别这是什么样的URL；或者指引到该网站的管理员界面，如果访问控制没有做好将导致一般用户可以直接进入管理界面。

**重定向和转发检查列表：**

- 重定向之前，验证重定向的目标URL
- 使用白名单验证重定向目标。
- 如果在网站内重定向，可以使用相对路径URL
- 重定向或者转发之前，要验证用户是否有权限访问目标URL

# 十、HTTP详解

**什么是HTTP？**

**1. 报文结构**

![](http://longls777.oss-cn-beijing.aliyuncs.com/img/z1.png)

![](http://longls777.oss-cn-beijing.aliyuncs.com/img/z2.png)

![](http://longls777.oss-cn-beijing.aliyuncs.com/img/z3.png)

![](http://longls777.oss-cn-beijing.aliyuncs.com/img/z4.png)



**2. HTTP状态码**

| 分类 | 分类描述                                       |
| ---- | ---------------------------------------------- |
| 1**  | 信息，服务器收到请求，需要请求者继续执行操作   |
| 2**  | 成功，操作被成功接收并处理                     |
| 3**  | 重定向，需要进一步的操作以完成请求             |
| 4**  | 客户端错误，请求包含语法错误或无法完成请求     |
| 5**  | 服务器错误，服务器在处理请求的过程中发生了错误 |

- 200 OK：请求成功。一般用于GET与POST请求
- 301 Moved Permanently：永久重定向
- 302 Found：临时重定向
- 400 Bad Request：客户端请求的语法错误，服务器无法理解
- 401 Unauthorized：请求未经授权
- 403 Forbidden：服务器理解请求客户端的请求，但是拒绝执行此请求
- 404 Not Found：请求的资源不存在
- 500 Internal Server Error：服务器内部错误，无法完成请求
- 503 Service Unavailable：服务器当前不能处理客户端的请求，一段时间后可能恢复正常

**3. HTTP1.0和HTTP1.1的主要区别**

- **长连接**：在HTTP/1.0中，**默认**使用的是短连接（HTTP1.0也支持长连接，connection：keep-alive），而HTTP/1.1默认是长连接
- **流水线：**HTTP/1.1支持流水线，可以减少整体的响应时间
- **错误状态响应码**：在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除
- **缓存处理**：在HTTP1.0中主要使用header里的If-Modified-Since，Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since，If-Match，If-None-Match等更多可供选择的缓存头来控制缓存策略。（详见HTTP缓存策略）
- **带宽优化及网络连接的使用**：HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能（关于断点续传的应用场景，例如用户需要下载一个大文件，最佳的方式是将这个大文件分割成几部分，然后由多个进程同时进行），HTTP1.1则在请求头引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就方便了开发者自由的选择以便于充分利用带宽和连接。（支持分块传输编码：可以把数据分成多块，让浏览器逐步显示页面）
- **HOST头域：**在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）

**4. URI和URL的区别**

- URI（Uniform Resource Identifier）是统一资源标志符，可以唯一标识一个资源。
- URL（Uniform Resource Location）是统一资源定位符，可以提供该资源的路径。它是一种具体的 URI，即 URL 可以用来标识一个资源，而且还指明了如何 locate 这个资源。

URI的作用像身份证号一样，URL的作用更像家庭住址一样。URL是一种具体的URI，它不仅唯一标识资源，而且还提供了定位该资源的信息，URL是URI的子集。

**5. HTTP 和 HTTPS 的区别**

- 端口 ：HTTP的URL由“http://”起始且默认使用端口80，而HTTPS的URL由“https://”起始且默认使用端口443。

- 安全性和资源消耗： HTTP协议运行在TCP之上，所有传输的内容都是明文，客户端和服务器端都无法验证对方的身份。HTTPS是运行在SSL/TLS（安全套接层/传输层安全协议）之上的HTTP协议，SSL/TLS 运行在TCP之上。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。所以说，HTTP 安全性没有 HTTPS高，但是 HTTPS 比HTTP耗费更多服务器资源。

- - 对称加密：密钥只有一个，加密解密为同一个密码，且加解密速度快，典型的对称加密算法有DES、AES等；
  - 非对称加密：密钥成对出现（且根据公钥无法推知私钥，根据私钥也无法推知公钥），加密解密使用不同密钥（公钥加密需要私钥解密，私钥加密需要公钥解密），相对对称加密速度较慢，典型的非对称加密算法有RSA、DSA等

**6. HTTPS加密过程**

**HTTP存在安全问题：**

- 使用明文进行通信，内容可能会被窃听
- 不验证通信方的身份，通信方有可能伪装身份
- 无法证明报文的完整性，报文有可能遭遇篡改

**HTTPS加密**

![HTTPS](http://longls777.oss-cn-beijing.aliyuncs.com/img/HTTPS.png)

- HTTPS： 采用 对称加密 和 非对称加密 结合的方式来保护浏览器和服务端之间的通信安全。

**对称加密算法加密数据+非对称加密算法交换密钥+数字证书验证身份 = 安全**

![HTTPS加密流程](http://longls777.oss-cn-beijing.aliyuncs.com/img/HTTPS加密流程.png)

1. 客户使用HTTPS的URL访问服务器，要求与服务器建立SSL连接
2. 服务器接收到客户端请求后，将网站的证书信息（证书中包含公钥）发送一份给客户端
3. 客户端验证证书的合法性，包括可信性，是否吊销，过期时间和域名
4. 客户端使用公钥对对称密钥加密，发送给服务器
5. 服务器用私钥解密，拿到对称加密的对称密钥
6. 然后客户端和服务器就可以通过这个对称密钥加密数据，进行安全通信

**7. GET和POST比较**

- GET用于获取资源，而POST用于传输实体

- GET请求会被浏览器主动cache，而POST不会，除非手动设置（因为GET是幂等的）

- GET方式提交数据的大小（一般来说1024字节），HTTP协议并没有硬性限制，而是与浏览器、服务器、操作系统有关，而POST理论上来说没有大小限制，HTTP协议规范也没有进行大小限制，但实际上post所能传递的数据量根据取决于服务器的设置和内存大小

- GET参数通过URL传递，POST放在Request body中

- 安全的HTTP方法不会改变服务器状态，GET方法是安全的，而POST却不是，因为POST的目的是传送实体体内容，这个内容可能是用户上传的表单数据，上传成功之后，服务器可能把这个数据存储到数据库中，因此状态也就发生了改变。

- 幂等的 HTTP 方法，同样的请求被执行一次与连续执行多次的效果是一样的，服务器的状态也是一样的，GET方法是幂等的，而 POST 方法不是，所有的安全方法也都是幂等的（幂等的意味着对同一URL的多个请求应该返回同样的结果）

- GET产生一个TCP数据包；POST产生两个TCP数据包

- - 对于GET方式的请求，浏览器会把HTTP header和data一并发送出去，服务器响应200（返回数据）
  - 对于POST，浏览器先发送Header，服务器响应100 continue，浏览器再发送Data，服务器响应200 ok（返回数据）

在网络环境好的情况下，发一次包的时间和发两次包的时间差别基本可以无视。而在网络环境差的情况下，两次包的TCP在验证数据包完整性上，有非常大的优点。

并不是所有浏览器都会在POST中发送两次包，Firefox就只发送一次。

**8. 短连接与长连接**

在HTTP/1.0中，默认使用的是短连接，默认Connection： close，也就是说每次HTTP请求都要重新建立一次连接。HTTP 是基于TCP/IP协议的，每一次建立或者断开连接都需要三次握手四次挥手的开销，如果每次请求都要这样的话，开销会比较大。因此最好能维持一个长连接，可以用一个长连接来发多个请求。HTTP 1.1起，默认使用长连接 ,默认开启Connection： keep-alive

**长连接和短连接的优缺点**

1）长连接可以省去较多建立连接和关闭连接的操作，比较节省资源和时间，但长连接如果一直存在的话，需要很多探测包的发送来维持这个连接，对服务器将是很大的负荷

2）相对而言短连接则不需要服务器承担太大负荷，只要存在的连接就都是有用连接，但如果客户端请求频繁，就会在TCP的建立连接和关闭连接上浪费较大的资源和时间 

**什么时候使用长连接，什么时候使用短连接呢？**

长连接：长连接多用于操作频繁，点对点的通讯，而且连接数不能太多情况。每个TCP连接都需要三步握手，这需要时间，如果每个操作都是先连接，再操作的话那么处理速度会降低很多，所以每个操作完后都不断开，处理时直接发送数据包就好，不用建立 TCP 连接（例如：数据库的连接用长连接，如果用短连接频繁的通信会造成 socket 错误，而且频繁的 socket 创建也是对资源的浪费）

 短连接：网站的 http 服务一般都用短链接，因为长连接对于服务端来说会耗费一定的资源，例如：类似WEB 网站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源，如果用长连接，而且同时有成千上万的用户，如果每个用户都占用一个连接的话，服务器负荷很大，并发量大，但每个用户无需频繁操作情况下需用短连接好

**9. 流水线**

 HTTP/1.1的持续连接有非流水线方式和流水线方式 。流水线方式是客户在收到HTTP的响应报文之前就能接着发送新的请求报文，与之相对应的非流水线方式是客户在收到前一个响应后才能发送下一个请求。

默认情况下，HTTP 请求是按顺序发出的。下一个请求只有在当前请求收到应答过后才会被发出。由于会受到网络延迟和带宽的限制，在下一个请求被发送到服务器之前，可能需要等待很长时间。

流水线是在同一条长连接上发出连续的请求，而不用等待应答返回。这样可以避免连接延迟。理论上讲，性能还会因为两个 HTTP 请求有可能被打包到一个 TCP 消息包中而得到提升。就算 HTTP 请求不断的继续，尺寸会增加，但设置 TCP 的 MSS(Maximum Segment Size) 选项，仍然足够包含一系列简单的请求。

并不是所有类型的 HTTP 请求都能用到流水线：只有幂等性 idempotent 方式，比如 GET、HEAD、PUT 和 DELETE 能够被安全的重试，非幂等请求比如POST不能使用，因为请求之间可能会存在先后依赖关系。如果有故障发生时，流水线的内容要能被轻易的重试

今天，所有遵循 HTTP/1.1 的代理和服务器都应该支持流水线，虽然实际情况中还是有很多限制：一个很重要的原因是，目前没有现代浏览器默认启用这个特性

**10.HTTP和FTP的异同点**

**同：**

- 都是应用层协议
- 都运行在TCP上

**异：**

- HTTP是面向网页的，FTP是面向文件的

- FTP在整个会话期间保留用户状态信息，而HTTP是无状态的

- FTP是的控制信息是带外传送，HTTP的控制信息是带内传送

- - 带外传输是指：使用一个分离的控制链接，控制信息和数据传输由不同的进程
  - FTP使用两个TCP连接，一个是控制连接，一个是数据连接，客户发出的传送请求通过控制连接发送给服务器端的控制进程，但控制连接不用来传送文件，实际用于传输文件的是另外建立的数据连接

# 十一、HTTPS详解