---
title: 操作系统
tags: 八股
categories: Others
date: 2023-5-1 22:32:00
index_img: 
banner_img: 
math: true
---

# 一、操作系统概述

**说说什么是操作系统？**

- 操作系统本质上是一个运行在计算机内核态上的软件程序 ，用于管理计算机硬件和软件资源。 运行在电脑上的所有应用程序都通过操作系统来调用系统内存以及磁盘等等硬件
- 操作系统存在屏蔽了硬件层的复杂性，它将复杂的硬件抽象为接口提供给用户态程序
- 操作系统具有对硬件的完全访问权，它可以使用机器指令集的全部指令

![zxczxcVv](http://longls777.oss-cn-beijing.aliyuncs.com/img/zxczxcVv.png)

**说说系统调用？**

根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别：

1. 用户态（user mode）：用户态运行的进程可以直接读取用户程序的数据，但是只能使用机器指令的一个子集
2. 内核态（kernel mode）：可以简单的理解系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制

我们运行的程序基本都是运行在用户态，如果我们需要调用操作系统提供的内核态级别的子功能，我们就需要系统调用

也就是说在我们运行的用户程序中，凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。

这些系统调用按功能大致可分为如下几类：

- 设备管理：完成设备的请求或释放，以及设备启动等功能。
- 文件管理：完成文件的读、写、创建及删除等功能。
- 进程控制：完成进程的创建、撤销、阻塞及唤醒等功能。
- 进程通信：完成进程之间的消息传递或信号传递等功能。
- 内存管理：完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。

# 二、进程和线程

**1. 说说进程、线程和协程的区别？**

进程是程序的一次执行过程，线程是进程内的一个执行单元，一个进程可以拥有多个线程

**进程与线程的区别**

- 拥有资源：进程是资源分配的基本单位，线程不拥有资源，但是线程可以访问隶属于进程的资源

- - 引申到JVM运行时数据区：多个线程共享进程的堆和方法区 （JDK1.8 之后的元空间）资源，但是每个线程有自己的程序计数器、虚拟机栈 和 本地方法栈

- ![JDK运行时数据区域](http://longls777.oss-cn-beijing.aliyuncs.com/img/JDK运行时数据区域.png)

- 调度：线程是CPU调度和分派的基本单位，它是比进程更小的能独立运行的基本单位
- 系统开销：创建或撤销进程时，系统都需要为之分配或回收资源，如内存空间、IO设备等，这些开销远大于创建或撤销线程时的开销；在进行进程切换时，需要保存当前CPU环境以及新调度进程CPU环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销较小
- 通信方面：线程间通信可以通过直接读写同一进程中的数据进行通信，而进程通信需要借助IPC

**协程与线程的比较**

协程是一种用户态的轻量级线程，是比线程更加轻量的存在，一个线程可以拥有多个协程。

协程的特点有两个：

- 一是执行效率高，因为子程序切换不是线程切换，而是由程序自身控制，没有内核切换的开销，所以性能优势明显
- 二是不需要多线程的机制，因为只有一个线程，也不存在同时写变量冲突，所以可以不加锁地访问共享资源，执行效率比多线程高很多
- 线程进程都是同步机制，而协程是异步

**2. 进程和线程拥有的资源？**

![进程和线程拥有的资源](http://longls777.oss-cn-beijing.aliyuncs.com/img/进程和线程拥有的资源.png)

> 所谓进程地址空间（process address space），就是从进程的视角看到的地址空间，是进程运行时所用到的虚拟地址的集合。

**3. 并行和并发的区别？**

- 并发（concurrency）：指宏观上看起来两个程序在同时运行，比如说在单核cpu上的多任务。但是从微观上看两个程序的指令是交织着运行的，指令之间交错执行，在单个周期内只运行了一个指令。这种并发并不能提高计算机的性能，只能提高效率（如降低某个进程的响应时间）
- 并行（parallelism）：指严格物理意义上的同时运行，比如多核cpu，两个程序分别运行在两个核上，两者之间互不影响，单个周期内每个程序都运行了自己的指令，也就是运行了两条指令。这样说来并行的确提高了计算机的效率。所以现在的cpu都是往多核方面发展

# 三、进程状态

**说说进程有哪几种状态，是怎么切换的？**

- 创建状态（new）：进程正在被创建，尚未到就绪状态。
- 就绪状态（ready）：进程已处于准备运行状态，即进程获得了除了处理器之外的一切所需资源，一旦得到处理器资源（处理器分配的时间片）即可运行。
- 运行状态（running）：进程正在处理器上运行（单核 CPU 任意时刻只有一个进程处于运行状态）。
- 阻塞状态（waiting）：又称为等待状态，进程正在等待某一事件而暂停运行如等待某资源为可用或等待 IO 操作完成。即使处理器空闲，该进程也不能运行。
- 结束状态（terminated）：进程正在从系统中消失。可能是进程正常结束或其他原因中断退出运行。

![操作系统进程状态](http://longls777.oss-cn-beijing.aliyuncs.com/img/操作系统进程状态.png)

- 只有就绪态和运行态可以相互转换，其它的都是单向转换。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。

- 阻塞状态是缺少需要的资源从而由运行状态转换而来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。

**引申：Java线程生命周期**

![Java线程生命周期](http://longls777.oss-cn-beijing.aliyuncs.com/img/Java线程生命周期.png)

![Java线程状态转移图](http://longls777.oss-cn-beijing.aliyuncs.com/img/Java线程状态转移图.png)

# 四、进程间通信方式

**说说进程间通信的方式？**

- **管道/匿名管道（Pipes）** ：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信，是半双工的。
- **命名管道（Named Pipes）** ：命名管道也是半双工的，其严格遵循先进先出（first in first out）原则。命名管道以磁盘文件的方式存在，可以实现无亲缘关系进程间的通信。
- **消息队列（Message Queuing）** ：消息队列是消息的链表，存放在**内核**中并由IPC标识符标识，不同的消息队列直接是相互独立的。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。
- **信号量（Semaphores）** ：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。
- **共享内存（Shared memory）** ：使得多个进程可以访问同一块内存空间，不同进程可以立即看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。共享内存是 IPC最快捷的方式，因为共享内存方式的通信没有中间过程。
- **套接字（Socket）** : 此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。
- **信号（Signal）** ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；

> https://blog.csdn.net/a987073381/article/details/52006729

**具体说明**

**管道**

管道是一种最基本的IPC机制，作用于有血缘关系的进程之间，完成数据传递。调用pipe系统函数即可创建一个管道。有如下特质：

1. 其本质是一个伪文件（实为内核缓冲区）

2. 由两个文件描述符引用，一个表示读端，一个表示写端

3. 规定数据从管道的写端流入管道，从读端流出

4. 数据一旦被读走，便不在管道中存在，不可反复读取

5. 由于管道采用半双工通信方式。因此，数据只能在一个方向上流动

6. 只能在有公共祖先的进程间使用管道

![Linux创建进程](http://longls777.oss-cn-beijing.aliyuncs.com/img/Linux创建进程.png)

1. 父进程调用pipe函数创建管道，得到两个文件描述符fd[0]、fd[1]指向管道的读端和写端

2. 父进程调用fork创建子进程，那么子进程也有两个文件描述符指向同一管道

3. 父进程关闭管道读端，子进程关闭管道写端。父进程可以向管道中写入数据，子进程将管道中的数据读出。由于管道是利用环形队列实现的，数据从写端流入管道，从读端流出，这样就实现了进程间通信

**命名管道**

由于基于fork机制，所以管道只能用于父进程和子进程之间，或者拥有相同祖先的两个子进程之间（有亲缘关系的进程之间）。为了解决这一问题，Linux提供了FIFO方式连接进程。FIFO又叫做命名管道（named PIPE）

FIFO（First in，First out）为一种特殊的文件类型，它在文件系统中有对应的路径。当一个进程以读(r)的方式打开该文件，而另一个进程以写(w)的方式打开该文件，那么内核就会在这两个进程之间建立管道，所以FIFO实际上也由内核管理，不与硬盘打交道。之所以叫FIFO，是因为管道本质上是一个先进先出的队列数据结构，最早放入的数据被最先读出来，从而保证信息交流的顺序。FIFO只是借用了文件系统（file system，命名管道是一种特殊类型的文件，因为Linux中所有事物都是文件，它在文件系统中以文件名的形式存在）来为管道命名。写模式的进程向FIFO文件中写入，而读模式的进程从FIFO文件中读出。当删除FIFO文件时，管道连接也随之消失。FIFO的好处在于我们可以通过文件的路径来识别管道，从而让没有亲缘关系的进程之间建立连接。

**消息队列**

Linux的消息队列（queue）实质上是一个链表，它有消息队列标识符(queue ID)。 msgget创建一个新队列或打开一个存在的队列；msgsnd向队列末端添加一条新消息；msgrcv从队列中取消息， 取消息是不一定遵循先进先出的， 也可以按消息的类型字段取消息。

**消息队列与命名管道的比较**

消息队列跟命名管道有不少的相同之处，通过与命名管道一样，消息队列进行通信的进程可以是不相关的进程，同时它们都是通过发送和接收的方式来传递数据的。在命名管道中，发送数据用write，接收数据用read，则在消息队列中，发送数据用msgsnd，接收数据用msgrcv。而且它们对每个数据都有一个最大长度的限制。

与命名管道相比，消息队列的优势在于：

- 消息队列也可以独立于发送和接收进程而存在，从而消除了在同步命名管道的打开和关闭时可能产生的困难
- 同时通过发送消息还可以避免命名管道的同步和阻塞问题，不需要由进程自己来提供同步方法
- 接收程序可以通过消息类型有选择地接收数据，而不是像命名管道中那样，只能默认地接收

**信号量**

信号量是一种计数器，用于控制对多个进程共享的资源进行的访问。它们常常被用作一个锁机制，在某个进程正在对特定的资源进行操作时，信号量可以防止另一个进程去访问它。 

信号量是特殊的变量，它只取正整数值并且只允许对这个值进行两种操作：wait和signal。（P、V，或者称为up、down） 

P(sv)：如果sv的值大于0，就给它减1；如果它的值等于0，就挂起该进程的执行 

V(sv)：如果有其他进程因等待sv而被挂起，就让它恢复运行；如果没有其他进程因等待sv而挂起，则给它加1 

简单理解就是P相当于申请资源，V相当于释放资源 

# 五、进程间调度算法

**1. 进程调度算法的评价指标？**

- CPU利用率

![CPU利用率](http://longls777.oss-cn-beijing.aliyuncs.com/img/CPU利用率.png)

- 系统吞吐量：表示单位时间内完成多少作业

![系统吞吐量](http://longls777.oss-cn-beijing.aliyuncs.com/img/系统吞吐量.png)

- 周转时间：

![周转时间](http://longls777.oss-cn-beijing.aliyuncs.com/img/周转时间.png)

**2. 说说进程调度算法？**

**批处理系统中，用户操作比较少，调度算法的目标是保证吞吐量和周转时间（从提交到完成的时间）**

- **先到先服务（FCFS）调度算法**：非抢占式的调度算法，按照请求的顺序进行调度。有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长

- - 优点：简单，公平
  - 缺点：适合长进程，不适合短进程

- **最短作业优先（SJF）的调度算法**：非抢占式的调度算法，按估计运行时间最短的顺序进行调度。长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度

- - 优点：平均周转时间最短，可增大系统吞吐量
  - 缺点：不利于长进程，有可能出现“饥饿”现象

- **最短剩余时间优先（SRTN）调度算法 ：**最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待

- **高响应比优先调度算法：**综合考虑作业的等待时间和要求服务的时间，在每次调度时先计算各个作业/进程的响应比，选择响应比最高的作业/进程为其服务，是非抢占式的调度算法

- - 对于短作业来说，等待时间相同时，服务时间越短，优先级越高，因此比较有利于短作业；
  - 当服务时间相同时，等待时间越长的优先级越高，因此它实现的是先来先服务
  - 对于长作业来说，随着等待时间越来越久，其响应比也会越来越大，从而避免了长作业饥饿的问题。
  - 总的来说，该算法既照顾了短作业，又考虑了作业到达的先后次序，解决了长作业的饥饿问题，因此实现了一种较好的折中

- ![响应比计算方法](C:\Users\Lenovo\Desktop\响应比.png)

**交互式系统有大量的用户交互操作，调度算法的目标是快速响应**

- **时间片轮转调度算法**：将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。时间片轮转算法的效率和时间片的大小有很大关系：因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。而如果时间片过长，那么实时性就不能得到保证。

上下文切换：保存和装入寄存器的值和内存映像，更新各种表格和列表，清除和重新调入内存、高速缓存等

- **优先级调度**：为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。

![优先级调度算法](http://longls777.oss-cn-beijing.aliyuncs.com/img/优先级调度算法.png)

- **多级队列调度算法**：一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。每个队列优先权也不同，最上面的优先权最高。可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

- - **优先级越高的队列中，时间片就越小。**
  - 只有上一个队列没有进程在排队，才能调度当前队列上的进程。
  - 该算法是抢占式的。
  - 这样做的好处是明显的，对于短作业来说，可以很快的轮到并解决。对于长作业来说，一下子解决不了，可以放到下一条队列里，虽然等的时间久了，但是轮到自己的执行时间变长了，也可以接受，不容易产生饥饿现象。

- # 六、内存管理

- **1. 说说什么是虚拟内存？**

- - 操作系统将内存抽象成地址空间。每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页，这些页被映射到物理内存（页框）
  - 虚拟内存到物理内存的映射，也就是页到页框的映射是由内存管理单元（MMU）控制的，它通过页表存储虚拟页号到物理页框号的映射，从而找到对应的物理地址
  - 页表项中可以设置一些访问控制字段，比如访问位，修改位等，用于指明允许对页面中的内容进行何种操作
  - 虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存
  - RAM与磁盘之间的交换是以整个页面为单位进行的

- **2.为什么要引入虚拟内存？**

- 虚拟内存作为内存管理的工具。操作系统为每个进程提供了一个独立的页表，也就是独立的虚拟地址空间。多个虚拟页面可以映射到同一个物理页面上。

- - **简化链接：** 独立的地址空间允许每个进程的内存映像使用相同的基本格式，而不管代码和数据实际存放在物理内存的何处。
  - 例如：一个给定的linux系统上的每个进程都是用类似的内存格式，对于64为地址空间，代码段总是从虚拟地址0x400000开始，数据段，代码段，栈，堆等等。
  - **加载器从不在磁盘到内存实际复制任何数据，在每个页初次被引用时，虚拟内存系统会按照需要自动的调入数据页。**
  - **简化内存分配：** 虚拟内存向用户提供一个简单的分配额外内存的机制。当一个运行在用户进程中的程序要求额外的堆空间时（如malloc），OS分配一个适当k大小个连续的虚拟内存页面，并且将他们映射到物理内存中任意位置的k个任意物理页面，**因此操作系统没有必要分配k个连续的物理内存页面，页面可以随机的分散在物理内存中**。
  - 虚拟内存作为内存保护的工具，不应该允许一个用户进程修改它的只读段，也不允许它修改任何内核代码和数据结构，不允许读写其他进程的私有内存，不允许修改任何与其他进程共享的虚拟页面。每次CPU生成一个地址时，MMU会读一个PTE（页表项），通过在PTE上添加一些额外的许可位来控制对一个虚拟页面内容的访问十分简单。

- **3. 为什么不能暴露物理地址？**

- - 容易被程序破坏操作系统
  - 难以同时运行多个程序

- **3. 说说缺页中断？**

- - 当程序访问了一个未映射的页面时，CPU会陷入到操作系统，这就是缺页中断
  - 当引发缺页中断时，操作系统通过页面置换算法将一个很少使用的页面调出内存，然后将需要访问的页面读入刚才回收的页框中，修改映射关系，重新启动引发缺页中断的指令

- **4. 虚拟内存地址到物理内存地址是如何映射的？**

- - 虚拟地址被分成虚拟页号（高位部分）和偏移量（低位部分）两部分
  - 虚拟页号作页表的索引，以找到该虚拟页面对应的页表项，由页表项找到页框号，然后把页框号拼接到偏移量的高位端，以替换虚拟页号，形成物理地址

- **5. 说说页表？**

- ![](http://longls777.oss-cn-beijing.aliyuncs.com/img/lkmlnlk.png)

- 页表类似一个函数，参数是虚拟页号，结果是物理页框号，这个函数可以把虚拟地址中的虚拟页号替换为页框号，从而形成物理地址

- 保护位：指出该页面允许一个什么类型的访问，如0表示读/写，1表示只读

- 修改位：也叫脏位，记录这个页面是否被修改过，如果是干净的就可以直接丢弃，脏的页面就必须写回磁盘

- 访问位：记录该页面被访问的信息，用来帮助操作系统在发生缺页异常时选择淘汰的页面

- 页表储存位置：

- - 单级页表：内存
  - 多级页表：高级 - 内存  低级 - 硬盘

**6. 如何提高虚拟地址到物理地址的映射速度？**

- 大多数程序总是对少量页面进行多次访问，所以使用快表（转换检测缓冲区，TLB）来存储这部分经常使用的页表，可以将快表理解为一种高速缓存器，当系统需要进行地址转换时，它先访问快表，这样可以加快地址转换的速度
- 由于采用页表做地址转换，读写内存数据时 CPU 要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。

**7. 如何解决解决虚拟地址空间大，页表会很大的问题？**

通过使用多级页表来避免把全部页表放在内存中占用过多空间，比如32位地址空间大小是4GB，一级目录包含1024个页表项，每个页表项指向一个包含4M地址大小的二级页表

- 二级页表可以不存在：如果某个一级页表的页表项没有被使用到，那么也就不需要创建对应的二级页表

- 二级页表可以不在主存：就相当于把二级页表当成了页框，当需要某个页面时再从磁盘中将其调入主存，利用了程序运行的局部性原理

  **8. 说说分页和分段的区别？**

- 对程序员的透明性：分页仅仅是由于系统管理的需要，而不是用户的需要（对用户透明），但是分段需要程序员显式划分每个段。

- 地址空间的维度：分页是一维地址空间，分段是二维的，需要通过段名和段内地址两个条件来标识一个地址。

- 大小是否可以改变：页的大小不可变，段的大小可以动态改变。

- 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使**程序**和**数据**可以被划分为逻辑上独立的地址空间并且有助于**共享**和**保护**。

# 七、页面置换算法

**说说页面置换算法？**

在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。

页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。

页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）

**FIFO页面置换算法**

选择换出的页面是最先进入的页面。

该算法会将那些经常被访问的页面换出，导致缺页率升高。

**LRU （Least Recently Used）页面置换算法（最近最久未使用）** 

LRU算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。

为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

**NRU（Not Recently Used）页面置换算法（最近未使用）**

每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。可以将页面分成以下四类：

- R=0，M=0
- R=0，M=1
- R=1，M=0
- R=1，M=1

当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。

NRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。

**NFU（Not Frequently Used）页面置换算法（老化算法）**

![老化算法](http://longls777.oss-cn-beijing.aliyuncs.com/img/老化算法.png)

- 在每次时钟中断时，操作系统扫描内存中所有页面，将每个页面的R位加到它的计数器上

- 发生缺页中断时，置换计数器值最小的页面

- 老化算法和LRU的区别：

- - 当两个页面未使用时间相同时，老化算法可以根据前几次访问的信息来选择淘汰哪个页面，比如：e图中的3和5
  - 老化算法只有有限个位数，如果都是00000000..，那么就无法判断该淘汰哪个页面

**第二次机会算法**

FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：

当页面被访问（读或写）时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。

![第二次机会算法](http://longls777.oss-cn-beijing.aliyuncs.com/img/第二次机会算法.png)

**OPT 页面置换算法（最佳页面置换算法）** 

最佳（Optimal, OPT）置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面，这样可以保证获得最低的缺页率。但由于人们目前无法预知进程在内存下的若干页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现。一般作为衡量其他置换算法的方法。

# 八、死锁和处理方法

**说说死锁？**

**什么是死锁？**

- 如果一个进程集合中的每个进程都在等待只能由该进程集合中的其他进程才能引发的事件，那么该进程集合就是死锁的
- 这个时间通常是释放进程所占有的资源（资源死锁）

**死锁出现的必要条件？**

- **互斥**：每个资源要么已经分配给了一个进程，要么就是可用的。
- **占有和等待**：已经得到了某个资源的进程可以再请求新的资源。
- **不可抢占**：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。
- **环路等待**：死锁发生时，系统中一定有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。
- 死锁发生时，上述四个条件一定是同时满足的

**死锁的处理方法？**

**鸵鸟策略**

把头埋在沙子里，假装根本没发生问题。

因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。

当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。

大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。

**死锁检测与死锁恢复**

不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。

- 利用抢占恢复：在不通知原进程的情况下，将某一资源从一个进程强行取走给另一个进程使用，接着又送回
- 利用回滚恢复：检测到死锁后回滚到较早的进程检查点

进程检查点：周期性地将进程的状态写入一个文件以备以后重启，该检查点包含了资源状态等信息

- 通过杀死进程恢复

**死锁预防**

破坏死锁的产生条件

- 破坏互斥条件：例如	允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程
- 破坏占有和等待条件：一种实现方式是规定所有进程在开始执行前请求所需要的全部资源
- 破坏不可抢占条件：当一个进程获得某种不可抢占资源，提出新的资源申请，若不能满足，则释放所有资源，以后需要，再次重新申请
- 破坏环路等待：给资源统一编号，进程只能按编号顺序来请求资源

**死锁避免**

系统对进程发出的每一个系统能够满足的资源申请进行动态检查，并根据检查结果决定是否分配资源；如果分配后系统可能发生死锁，则不予分配，否则予以分配。这是一种保证系统不进入死锁状态的动态策略。例如：银行家算法

**什么是活锁？（拓展）**

活锁与死锁恰恰相反，死锁是大家都拿不到资源，占用着对方的资源，而活锁是拿到资源却又相互释放而不执行。线程相互谦让，都主动将资源释放给别的线程执行，这样资源在多个线程之间来回跳动而又得不到执行，这就是活锁

# 九、操作系统中的锁

**操作系统中有哪些锁？**

- **信号量（Semaphore）**：信号量分为二元信号量和多元信号量，所谓二元信号量就是指该信号量只有两个状态，要么被占用，要么空闲；而多元信号量则允许同时被N个线程占有，超出N个外的占用请求将被阻塞。信号量是“系统级别”的，即同一个信号量可以被不同的进程访问。
- **互斥量（Mutex）**：和二元信号量类似， 唯一不同的是，互斥量的获取和释放必须是在同一个线程中进行的。如果一个线程去释放一个并不是它所占有的互斥量是无效的。而信号量是可以由其它线程进行释放的。
- **临界区（Critical Section）**：把临界区的锁的获取称为进入临界区，而把锁的释放称为离开临界区。任何两个进程不能同时处于同一个临界区
- **读写锁（Read-Write Lock）**：适用于一个特定的场合。比如对于一段线程间访问的数据，如果程序大部分时间都是在读取，而只有很少的时间才会写入，那么使用前面几种锁时，每次读取也是同样 要申请锁的，而这时其它的线程就无法再对此段数据进行读取。可是，多个线程同时对一段数据进行读取时，是不存在同步问题的，那么这些读取时设置的锁就影响 了程序的性能。读写锁的出现就是为了解决这个问题的。对于一个读写锁，有两种获取方式：共享（Shared）或独占 （Exclusive）。如果当前读写锁处于空闲状态，那么当多个线程同时以共享方式访问该读写锁时，都可以成功；而此时如果一个线程以独占的方式访问该 读写锁，那么它会等待所有共享访问都结束后才可以成功。在读写锁被独占访问的过程中，再次共享和独占请求访问该锁，都会进入等待状态。

# 十、手撕LRU

```java
class LRUCache {

    class Node{
        int key;
        int value;
        Node prev;
        Node next;
        public Node(){}
        public Node(int key,int value){this.key = key;this.value = value;}
    }

    private Map<Integer,Node> cache = new HashMap<>();
    private int size;
    private int capacity;
    private Node head, tail; 
    public LRUCache(int capacity) {
        this.size = 0;
        this.capacity = capacity;
        head = new Node();
        tail = new Node();
        head.next = tail;
        tail.prev = head;
    }
    
    public int get(int key) {
        Node node = cache.get(key);
        if(node==null) return -1;
        moveToHead(node);
        return node.value;
    }
    
    public void put(int key, int value) {
        Node node = cache.get(key);
        if(node==null){
            Node newNode = new Node(key,value);
            cache.put(key,newNode);
            addToHead(newNode);
            size++;
            if(size>capacity){
                Node tail = removeTail();
                cache.remove(tail.key);
                --size;
            }

        }else{
            node.value = value;
            moveToHead(node);
        }

    }
    private void addToHead(Node node){
        node.prev = head;
        node.next = head.next;
        head.next.prev = node;
        head.next = node;
    }
    private void moveToHead(Node node){
        removeNode(node);
        addToHead(node);
    }
    private void removeNode(Node node){
        node.next.prev = node.prev;
        node.prev.next = node.next;
    }
    private Node removeTail(){
        Node res = tail.prev;
        removeNode(res);
        return res;
    }
}
```

- 删除节点
- 添加节点到head
- 移动节点到head（删除节点+添加节点到head）
- 删除尾部节点