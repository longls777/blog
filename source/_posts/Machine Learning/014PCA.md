---
title: PCA
tags: 
categories: Machine Learning
date: 2023-8-1 20:25:00
index_img: http://longls777.oss-cn-beijing.aliyuncs.com/img/v2-e47296e78fff3d97eea11d0657ddcb81_720w.jpg
banner_img: http://longls777.oss-cn-beijing.aliyuncs.com/img/v2-e47296e78fff3d97eea11d0657ddcb81_720w.jpg
math: true
---

> 【机器学习】降维——PCA（非常详细） - 阿泽的文章 - 知乎 https://zhuanlan.zhihu.com/p/77151308 写的确实很详细

![](http://longls777.oss-cn-beijing.aliyuncs.com/img/v2-e47296e78fff3d97eea11d0657ddcb81_720w.jpg)

## 定义

Principal Component Analysis 主成分分析

常用于高维数据的降维，可用于提取数据的主要特征分量



## 推导	

目的：**寻找一个一维基，使得所有数据变换为这个基上的坐标表示后，方差值最大**

![](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230801210356479.png)

> 更具体的推导过程请参考文章开头的引用链接

## 求解步骤

![](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230801204807287.png)



## 性质

1. **缓解维度灾难**：PCA 算法通过舍去一部分信息之后能使得样本的采样密度增大（因为维数降低了），这是缓解维度灾难的重要手段；
2. **降噪**：当数据受到噪声影响时，最小特征值对应的特征向量往往与噪声有关，将它们舍弃能在一定程度上起到降噪的效果；
3. **过拟合**：PCA 保留了主要信息，但这个主要信息只是针对训练集的，而且这个主要信息未必是重要信息。有可能舍弃了一些看似无用的信息，但是这些看似无用的信息恰好是重要信息，只是在训练集上没有很大的表现，所以 PCA 也可能加剧了过拟合；
4. **特征独立**：PCA 不仅将数据压缩到低维，它也使得降维之后的数据各特征相互独立；



## 为什么用SVD求解PCA？

![](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230801205622108.png)

5.**数值稳定性**：通过 SVD 可以得到与 PCA 相同的结果，但是 SVD 通常比直接使用 PCA 更稳定。PCA 需要计算 $X^TX$ 的值，对于某些矩阵，求协方差时很可能会丢失一些精度



## PCA 的优化目标是什么？

​	最大化投影后方差 + 最小化到超平面距离



## PCA 白化是什么？白化的作用是什么？

通过PCA投影以后（消除了特征之间的相关性），在各个坐标上除以方差（方差归一化）

PCA白化是一种重要的预处理过程，其目的就是降低输入数据的冗余性，使得经过白化处理的输入数据具有如下性质：

- 特征之间相关性较低
- 所有特征具有相同的方差



## PCA与SVD对比

![PCA vs SVD](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230801212058518.png)