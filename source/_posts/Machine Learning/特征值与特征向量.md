---
title: 特征值与特征向量
tags: 
categories: Machine Learning
date: 2022-10-13 16:25:00
index_img: http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20221013160652989.png
banner_img: http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20221013160652989.png
math: true
---

## 特征值与特征向量

- 特征值分解可以得到特征值与特征向量
- **特征值表示的是这个特征到底有多重要，而特征向量表示这个特征是什么**

矩阵A 的特征值与其特征向量$\vec{v}$, 特征值 λ 满足： $$ A\nu = \lambda \nu $$

将矩阵分解为它的特征值与特征向量的过程被称为**“特征分解”**（Eigendecomposition），又称**"谱分解"**（Spectral decomposition）

特征值分解是将一个矩阵分解为如下形式：
$$
A=Q\sum Q^{-1}
$$
$Q$：矩阵A的特征向量组成的矩阵

$\sum$:一个对角矩阵，每一个对角元素是一个特征值，里面的特征值是由大到小排列的，这些特征值所对应的特征向量就是描述这个矩阵变化方向（从主要的变化到次要的变化排列）。 特征值分解表示矩阵$A$的信息可以由其特征值和特征向量表示。



> https://mp.weixin.qq.com/s/M1yUVXy89vUt0AUBj9SGDQ
>
> https://github.com/songyingxin/NLPer-Interview/blob/master/1-%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0.md















> https://github.com/songyingxin/NLPer-Interview/blob/master/1-%E5%9F%BA%E7%A1%80%E6%95%B0%E5%AD%A6%E7%9F%A5%E8%AF%86/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0.md