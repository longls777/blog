---
title: L1和L2正则化
tags: 
categories: AI
date: 2023-7-20 10:24:00
index_img: http://longls777.oss-cn-beijing.aliyuncs.com/img/v2-e3aab047113ebd0b3dfb6ec014059e64_1440w.webp
banner_img: http://longls777.oss-cn-beijing.aliyuncs.com/img/v2-e3aab047113ebd0b3dfb6ec014059e64_1440w.webp
math: true
---

![L1正则化参数的选择](http://longls777.oss-cn-beijing.aliyuncs.com/img/aHR0cDovL2ltZy5ibG9nLmNzZG4ubmV0LzIwMTYwOTA0MTg0ODAyNjY4)

- 什么是L1和L2正则化？
- L1正则化的作用是什么？
- L1为什么可以实现稀疏化？
- 稀疏化的作用是什么？（特征选择）
- 为什么L2不能产生稀疏模型？
- L2正则化如何防止过拟合？
- L1正则化如何防止过拟合？
- 什么是shirnk to zero？如何据此选择正则化参数？

> https://blog.csdn.net/jinping_shi/article/details/52433975



![L1和L2的几何意义](http://longls777.oss-cn-beijing.aliyuncs.com/img/v2-e3aab047113ebd0b3dfb6ec014059e64_1440w.webp)

- L2的本质是什么？ 权重衰减
- L1和L2的贝叶斯视角？L1-拉普拉斯分布，L2-高斯分布
- Forward Selection & Forward Stagewise & Least Squares Boosting
- LARS 最小角回归是什么？
- Lasso的三种解法

> 从Lasso开始说起 - 李新春的文章 - 知乎 https://zhuanlan.zhihu.com/p/46999826