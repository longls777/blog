---
title: 逻辑回归
tags: 
categories: AI
date: 2023-7-20 19:45:00
index_img:
banner_img:
math: true
---

> https://blog.csdn.net/perfect1t/article/details/82966647

逻辑回归主要用于二分类，其主要思想是：**根据现有数据对分类边界线建立回归公式，以此进行分类**

将线性回归$z = w^Tx + b$ 输入到sigmoid函数$y = \frac{1}{1+e^{-z}}$：
$$
y = \frac{1}{1 + e^{-(w^Tx+b)}}
$$
从而得到：
$$
ln\frac{y}{1-y} = w^Tx+b
$$
$y$为正例的概率，$1-y$为负例的概率，则$\frac{y}{1-y}$称为几率，反映了作为正例的相对可能性。对几率取对数称为对数几率（logit）

**实际上在利用线性回归模型的预测结果去逼近真实label的对数几率**

****

#### 使用最大似然估计求解：

> 对数损失函数（logLoss，也就是二元交叉熵损失）

![](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230720200615852.png)

最小化该损失函数即可