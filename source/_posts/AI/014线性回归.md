---
title: 线性回归公式推导
tags: 
categories: AI
date: 2023-7-25 15:03:00
index_img: http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230725155834810.png
banner_img: http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230725155834810.png
math: true
---

## Linear Regression

![线性回归](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230725155834810.png)

拟合函数：
$$
h_{\theta}=\theta_0+\theta_1x_1+\theta_2x_2
$$
其中$\theta_i$为权重，化简得到：
$$
h_{\theta}(x)=\sum_{i=0}^{n}\theta_ix_i=\theta^Tx
$$
设误差为$\epsilon$：
$$
y^{(i)}=\theta^Tx^{(i)} + \epsilon^{(i)}
$$
假设误差独立同分布，且$\epsilon \sim N(0, \sigma^2)$：
$$
p(\epsilon^{(i)})=\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{\left( \epsilon^{(i)} \right)^2}{2 \sigma^2}\right)
$$
所以：
$$
p\left(y^{(i)} \mid x^{(i)} ; \theta\right)=\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{\left(y^{(i)}-\theta^T x^{(i)}\right)^2}{2 \sigma^2}\right)
$$
引入似然函数：
$$
L(\theta)=\prod_{i=1}^{m}p\left(y^{(i)} \mid x^{(i)} ; \theta\right)=\prod_{i=1}^{m}\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{\left(y^{(i)}-\theta^T x^{(i)}\right)^2}{2 \sigma^2}\right)
$$
对数似然：
$$
log(L(\theta))=log\prod_{i=1}^{m}\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{\left(y^{(i)}-\theta^T x^{(i)}\right)^2}{2 \sigma^2}\right)\\ 
=\sum_{i=1}^{m}log\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{\left(y^{(i)}-\theta^T x^{(i)}\right)^2}{2 \sigma^2}\right)\\
=m\cdot log\frac{1}{\sqrt{2 \pi} \sigma} - \frac{1}{\sigma^2} \cdot \frac{1}{2}\sum_{i=1}^{m} \left(y^{(i)}-\theta^T x^{(i)}\right)^2
$$
最小化负对数似然（maximum likelihood estimation，MLE，最大似然估计），即最小化$J(\theta)$：
$$
J(\theta)=\frac{1}{2}\sum_{i=1}^{m} \left(y^{(i)}-\theta^T x^{(i)}\right)^2
$$
求解过程：
$$
J(\theta)=\frac{1}{2} \sum_{i=1}^m\left(h_\theta\left(x^{(i)}\right)-y^{(i)}\right)^2=\frac{1}{2}(X \theta-y)^T(X \theta-y) \\
$$

$$
\nabla_\theta J(\theta)=\nabla_\theta\left(\frac{1}{2}(X \theta-y)^T(X \theta-y)\right)=\nabla_\theta\left(\frac{1}{2}\left(\theta^T X^T-y^T\right)(X \theta-y)\right) \\
=\nabla_\theta\left(\frac{1}{2}\left(\theta^T X^T X \theta-\theta^T X^T y-y^T X \theta+y^T y\right)\right) \\
=\frac{1}{2}\left(2 X^T X \theta-X^T y-\left(y^T X\right)^T\right)=X^T X \theta-X^T y \\
$$

令$\nabla_\theta J(\theta)=0$得到：
$$
\quad \theta=\left(X^T X\right)^{-1} X^T y
$$

> 其中使用到的矩阵运算法则：
>
> $(A+B)^T=(A^T+B^T)$
>
> $(AB)^T=B^TA^T$
>
> $\nabla_x(x^TAx)=Ax+A^Tx$
>
> $\nabla_xx^TA=A$
>
> $\nabla_xAx=A^T$



## 引申：为什么选择均方差损失函数作为线性回归的损失函数？

在假设**误差项服从独立同分布的正态分布**时，**最小化均方差损失函数等价于最大似然估计的解**

![](http://longls777.oss-cn-beijing.aliyuncs.com/img/image-20230725161719400.png)

