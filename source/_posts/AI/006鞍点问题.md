---
title: 鞍点问题
tags: 
categories: AI
date: 2023-7-21 15:21:00
index_img: http://longls777.oss-cn-beijing.aliyuncs.com/img/20200626110310593.png
banner_img: http://longls777.oss-cn-beijing.aliyuncs.com/img/20200626110310593.png
math: true
---

> https://blog.csdn.net/qq_39852676/article/details/106967368

![鞍点](http://longls777.oss-cn-beijing.aliyuncs.com/img/20200626113909713.png)

## 鞍点和局部最优点

- 鞍点： 鞍点是一个多元函数在某一点处的局部最小值和局部最大值共存的点。在鞍点处，函数在某些方向上是局部最小值，而在其他方向上是局部最大值。鞍点的形状类似于马鞍，因此得名。在二维空间中，鞍点通常是函数曲线上的一个拐点，在高维空间中，鞍点也是函数在某些方向上是凸函数，而在其他方向上是凹函数的点。

- 局部最优点： 局部最优点是指在函数曲线上某一局部范围内具有最小值（或最大值）的点。它是一个局部性质的概念，即函数在该点附近比其他点更小（或更大），但并不要求该点是全局最小值（或最大值）。局部最优点是优化问题的一个解，但并不保证是全局最优解。



## 神经网络难以优化的原因是什么？

神经网络通常具有非常复杂的非线性结构，导致损失函数往往是非凸的。非凸函数存在多个**局部最优点、鞍点和平坦区域**，使得寻找全局最优解变得十分困难。优化算法可能会陷入局部最优点或鞍点附近而无法继续优化



## 如何判断是鞍点还是局部最优点？

这时候就需要用到神经网络的loss surface的Hessian矩阵，通过计算Hessian矩阵的特征值，我们就可以确定神经网络的解属于那种类型：

- 当Hessian矩阵的特征值有正有负的时候，神经网络的一阶导数为零的点为鞍点
- 当Hessian矩阵的特征值全部为非负的时候，神经网络的一阶导数为零的点为局部极小值点



## 如何解决鞍点问题？

- 默认使用的`mini-batch`梯度下降法本身就是有噪声的梯度估计，哪怕位于梯度为0的点，也经常在某个`mini-batch`下的估计把它估计偏了，导致往前或者往后挪了一步摔下马鞍，**也就是`mini-batch`的梯度下降法使得模型很容易逃离特征空间中的鞍点**

- 更多的，我们可以从以下方面考虑：
  - 如何去设计一个尽量没有“平坦区”等危险地形的loss空间，即着手于loss函数的设计以及深度学习模型的设计；
  - 尽量让模型的初始化点远离空间中的危险地带，让最优化游戏开始于简单模式，即着手于模型参数的初始化策略；
  - 让最优化过程更智能一点，该加速冲时加速冲，该大胆跳跃时就大胆跳，该慢慢踱步时慢慢走，对危险地形有一定的判断力，如梯度截断策略；
  - 开外挂，本来下一步要走向死亡的，结果被外挂给拽回了安全区，如batch normalization策略等

## 模型训练陷入鞍点的现象？

神经网络在学习过程中如果遇到鞍点，出现的直接现象是导致训练速度时间变长，这是因为神经网络是一个多维的神经网络，需要计算各个方向上的纬度，从而寻找出最优的路线，逃出鞍点